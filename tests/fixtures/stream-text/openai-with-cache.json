{
  "name": "ai.streamText.doStream",
  "attributes": {
    "operation.name": "ai.streamText.doStream",
    "ai.operationId": "ai.streamText.doStream",
    "ai.model.provider": "openai.responses",
    "ai.model.id": "gpt-5-mini",
    "ai.settings.maxRetries": 2,
    "ai.prompt.messages": "[{\"role\":\"system\",\"content\":\"You are a helpful assistant with extensive knowledge and capabilities. Your primary function is to provide accurate, comprehensive, and contextually appropriate responses to user queries across a wide range of topics including but not limited to science, technology, mathematics, literature, history, philosophy, arts, and general knowledge. You should always strive to be informative, clear, and engaging in your communication style. When responding to questions, consider multiple perspectives and provide well-reasoned explanations. If you're uncertain about something, acknowledge that uncertainty rather than providing potentially incorrect information. You should be respectful of different viewpoints and cultural sensitivities while maintaining objectivity. Your responses should be tailored to the apparent knowledge level and needs of the user, providing appropriate depth and complexity. When dealing with complex topics, break them down into understandable components and use examples or analogies when helpful. You should also be proactive in asking clarifying questions when the user's intent is ambiguous. Additionally, you should maintain a professional yet approachable tone throughout all interactions, being neither overly formal nor too casual. Your goal is to be genuinely helpful and to facilitate learning and understanding. You should also be aware of potential biases in your training data and strive to provide balanced perspectives. When appropriate, encourage critical thinking and independent verification of information, especially for important decisions or controversial topics. Remember that your role is to assist and inform, not to make decisions for users or to provide advice that could have significant personal, legal, or medical consequences without appropriate disclaimers.\"},{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":\"Paragraph 1: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 2: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 3: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 4: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 5: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 6: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 7: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 8: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 9: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 10: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 11: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 12: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 13: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 14: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 15: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 16: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 17: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 18: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 19: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 20: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 21: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 22: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 23: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 24: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 25: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 26: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 27: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 28: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 29: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 30: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 31: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 32: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 33: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 34: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 35: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 36: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 37: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 38: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 39: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 40: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 41: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 42: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 43: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 44: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 45: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 46: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 47: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 48: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 49: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nParagraph 50: Telemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\\nCache-Buster: cache-buster-1758952782286-02ypyi\"}]}]",
    "gen_ai.system": "openai.responses",
    "gen_ai.request.model": "gpt-5-mini",
    "ai.response.msToFirstChunk": 1359.2236670000002,
    "ai.response.msToFinish": 8796.591542,
    "ai.response.avgOutputTokensPerSecond": 50.47409532204468,
    "ai.response.finishReason": "stop",
    "ai.response.text": "I see the same sentence repeated 50 times (Paragraphs 1–50). Would you like me to do any of the following? Pick one or tell me another:\n\n- Deduplicate and return a single clean paragraph (I can also remove the cache-buster).\n- Summarize or shorten the message.\n- Reword it for different tones (technical, marketing, user-facing).\n- Create a one-line headline or bullets highlighting key telemetry metrics.\n- Generate alternate phrasings for A/B testing.\n- Produce a short explainer (why each metric matters) or an action plan for teams.\n\nI can start by deduplicating and removing the cache-buster. Here’s the cleaned single paragraph:\n\nTelemetry gives real-time insight into prompt size, latency, cache hits, and per-user spend so teams can tune prompts, cap runaway agents, and stay on budget.\n\nWhich option do you want next?",
    "ai.response.id": "resp_68d77d59f8bc8196905cd5cbafeeb21e0456a7aa9c6fcff0",
    "ai.response.model": "gpt-5-mini-2025-08-07",
    "ai.response.timestamp": "2025-09-27T05:59:54.000Z",
    "ai.response.providerMetadata": "{\"openai\":{\"responseId\":\"resp_68d77d59f8bc8196905cd5cbafeeb21e0456a7aa9c6fcff0\",\"serviceTier\":\"default\"}}",
    "ai.usage.inputTokens": 2221,
    "ai.usage.outputTokens": 444,
    "ai.usage.totalTokens": 2665,
    "ai.usage.reasoningTokens": 256,
    "ai.usage.cachedInputTokens": 2048,
    "gen_ai.response.finish_reasons": [
      "stop"
    ],
    "gen_ai.response.id": "resp_68d77d59f8bc8196905cd5cbafeeb21e0456a7aa9c6fcff0",
    "gen_ai.response.model": "gpt-5-mini-2025-08-07",
    "gen_ai.usage.input_tokens": 2221,
    "gen_ai.usage.output_tokens": 444,
    "ai.telemetry.metadata.userId": "user-2",
    "ai.telemetry.metadata.workspaceId": "workspace-2"
  }
}